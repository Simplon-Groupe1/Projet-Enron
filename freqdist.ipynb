{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598359208534",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "100000000"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "csv.field_size_limit(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('sample.csv', 'r') as csvfile :\n",
    "    mail = csv.reader(csvfile, delimiter='|')\n",
    "    tokens=''\n",
    "    for message in mail:\n",
    "        tokens=tokens + message[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<FreqDist with 11369 samples and 106219 outcomes>\n[(\"'\", 36399), (',', 35010), (\"'for\", 747), (\"'to\", 442), (\"'of\", 436), (\"'and\", 419), (\"'re\", 405), (\"'the\", 328), (\"'s\", 304), (\"'on\", 262), (\"'enron\", 253), (\"'in\", 231), (\"'fw\", 219), (\"'01\", 215), (\"'hourahead\", 170), (\"'energy\", 167), (\"'from\", 162), ('4', 160), (\"'hour\", 148), (\"'date\", 147), (\"'gas\", 144), (\"'power\", 143), (\"'new\", 140), ('1', 135), (\"'10\", 131), (\"'meeting\", 131), (\"'11\", 128), (\"'with\", 122), (\"'2001\", 118), ('2', 115), (\"'codesite\", 114), (\"'your\", 111), (\"'report\", 108), (\"'start\", 102), ('e', 99), (\"'is\", 96), (\"'you\", 93), ('5', 91), (\"'com\", 89), (\"'conference\", 89), (\"'at\", 85), (\"'12\", 81), ('3', 80), (\"'request\", 80), (\"'credit\", 80), (\"'deal\", 72), (\"'trading\", 72), ('7', 70), ('6', 67), (\"'00\", 65), (\"'2000\", 64), (\"'daily\", 64), (\"'agreementre\", 64), (\"'eol\", 64), (\"'02\", 62), (\"'call\", 60), (\"'update\", 59), (\"'market\", 59), (\"'day\", 58), (\"'access\", 57), (\"'as\", 55), (\"'schedule\", 55), (\"'agreement\", 54), ('9', 53), (\"'letter\", 52), (\"'this\", 51), (\"'it\", 50), (\"'up\", 50), (\"'by\", 49), (\"'contract\", 47), (\"'21\", 47), (\"'october\", 47), ('p', 47), ('l', 47), (\"'inc\", 47), (\"'m\", 47), (\"'notification\", 47), (\"'30\", 47), (\"'meetingre\", 46), (\"'22\", 46), (\"'may\", 45), (\"'change\", 45), ('8', 45), (\"'01re\", 45), (\"'fwd\", 45), (\"'california\", 45), (\"'time\", 44), (\"'news\", 44), (\"'ferc\", 44), (\"'draft\", 43), (\"'master\", 43), (\"'no\", 42), (\"'management\", 42), (\"'today\", 42), (\"'lay\", 42), (\"'19\", 41), (\"'june\", 41), (\"'legal\", 41), (\"'risk\", 40), (\"'18\", 40)]\n"
    }
   ],
   "source": [
    "\n",
    "#tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "#tokens = str([t.lower() for t in tokenizer.tokenize(tokens)])\n",
    "tokenized_messages=nltk.word_tokenize(tokens)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "filtered_tokenized_messages = [word for word in tokenized_messages if word not in stopwords]\n",
    "fdist = FreqDist(filtered_tokenized_messages)\n",
    "common = fdist.most_common(100)\n",
    "#print(tokenized_messages)\n",
    "print(fdist)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}